{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<H1> Rock, Paper, Scissors Machine Learning Game </H1>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import the necessary libraries"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "from RPS_fun import *\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "y = y[:-2]\n",
    "X = X[:-1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Testing the AUC and ROC from the decision tree model created in the `RPS_fun.py` file."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n",
      "    Response_  Response_P  Response_R  Response_S\n",
      "62          0           1           0           0\n",
      "40          0           0           0           1\n",
      "94          0           0           1           0\n",
      "18          0           0           1           0\n",
      "81          0           0           1           0\n",
      "83          0           0           0           1\n",
      "64          0           0           1           0\n",
      "42          0           1           0           0\n",
      "10          0           0           1           0\n",
      "0           0           1           0           0\n",
      "31          0           0           0           1\n",
      "75          0           0           1           0\n",
      "47          0           1           0           0\n",
      "26          0           0           1           0\n",
      "44          0           1           0           0\n",
      "4           0           0           1           0\n",
      "22          0           0           1           0\n",
      "12          0           0           1           0\n",
      "90          0           0           0           1\n",
      "73          0           1           0           0\n",
      "49          0           0           1           0\n",
      "70          0           0           1           0\n",
      "68          0           1           0           0\n",
      "15          0           1           0           0\n",
      "39          0           0           0           1\n",
      "33          0           0           0           1\n",
      "9           0           0           0           1\n",
      "80          0           1           0           0\n",
      "11          0           1           0           0\n",
      "65          0           0           0           1\n",
      "93          0           0           1           0\n",
      "30          0           0           0           1\n",
      "28          0           1           0           0\n",
      "88          0           0           1           0\n",
      "5           0           1           0           0\n",
      "45          0           0           1           0\n",
      "69          0           0           1           0\n",
      "35          0           0           0           1\n",
      "16          0           0           1           0\n",
      "72          0           0           0           1\n",
      "34          0           0           0           1\n",
      "7           0           0           1           0\n",
      "55          0           0           1           0\n",
      "27          0           0           0           1\n",
      "19          0           0           0           1\n",
      "79          0           1           0           0\n",
      "25          0           0           0           1\n",
      "53          0           0           1           0\n",
      "13          0           1           0           0\n",
      "    Response_  Response_P  Response_R  Response_S\n",
      "0           0           1           0           0\n",
      "1           0           1           0           0\n",
      "2           0           1           0           0\n",
      "3           0           0           1           0\n",
      "4           0           0           1           0\n",
      "..        ...         ...         ...         ...\n",
      "93          0           0           1           0\n",
      "94          0           0           1           0\n",
      "95          0           0           0           1\n",
      "96          0           0           0           1\n",
      "97          0           1           0           0\n",
      "\n",
      "[98 rows x 4 columns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [61]\u001B[0m, in \u001B[0;36m<cell line: 7>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(test_lab)\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(y)\n\u001B[1;32m----> 7\u001B[0m \u001B[43mroc_auc_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_lab\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\OneDrive\\Desktop\\GitHub\\Python\\Rock-Paper-Scissors\\venv\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:577\u001B[0m, in \u001B[0;36mroc_auc_score\u001B[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001B[0m\n\u001B[0;32m    569\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _average_binary_score(\n\u001B[0;32m    570\u001B[0m         partial(_binary_roc_auc_score, max_fpr\u001B[38;5;241m=\u001B[39mmax_fpr),\n\u001B[0;32m    571\u001B[0m         y_true,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    574\u001B[0m         sample_weight\u001B[38;5;241m=\u001B[39msample_weight,\n\u001B[0;32m    575\u001B[0m     )\n\u001B[0;32m    576\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:  \u001B[38;5;66;03m# multilabel-indicator\u001B[39;00m\n\u001B[1;32m--> 577\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_average_binary_score\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    578\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpartial\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_binary_roc_auc_score\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_fpr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_fpr\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    579\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    580\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    581\u001B[0m \u001B[43m        \u001B[49m\u001B[43maverage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    582\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    583\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\OneDrive\\Desktop\\GitHub\\Python\\Rock-Paper-Scissors\\venv\\lib\\site-packages\\sklearn\\metrics\\_base.py:118\u001B[0m, in \u001B[0;36m_average_binary_score\u001B[1;34m(binary_metric, y_true, y_score, average, sample_weight)\u001B[0m\n\u001B[0;32m    116\u001B[0m     y_true_c \u001B[38;5;241m=\u001B[39m y_true\u001B[38;5;241m.\u001B[39mtake([c], axis\u001B[38;5;241m=\u001B[39mnot_average_axis)\u001B[38;5;241m.\u001B[39mravel()\n\u001B[0;32m    117\u001B[0m     y_score_c \u001B[38;5;241m=\u001B[39m y_score\u001B[38;5;241m.\u001B[39mtake([c], axis\u001B[38;5;241m=\u001B[39mnot_average_axis)\u001B[38;5;241m.\u001B[39mravel()\n\u001B[1;32m--> 118\u001B[0m     score[c] \u001B[38;5;241m=\u001B[39m \u001B[43mbinary_metric\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true_c\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_score_c\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mscore_weight\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    120\u001B[0m \u001B[38;5;66;03m# Average the results\u001B[39;00m\n\u001B[0;32m    121\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m average \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\OneDrive\\Desktop\\GitHub\\Python\\Rock-Paper-Scissors\\venv\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:338\u001B[0m, in \u001B[0;36m_binary_roc_auc_score\u001B[1;34m(y_true, y_score, sample_weight, max_fpr)\u001B[0m\n\u001B[0;32m    336\u001B[0m \u001B[38;5;124;03m\"\"\"Binary roc auc score.\"\"\"\u001B[39;00m\n\u001B[0;32m    337\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(np\u001B[38;5;241m.\u001B[39munique(y_true)) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m2\u001B[39m:\n\u001B[1;32m--> 338\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    339\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOnly one class present in y_true. ROC AUC score \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    340\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis not defined in that case.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    341\u001B[0m     )\n\u001B[0;32m    343\u001B[0m fpr, tpr, _ \u001B[38;5;241m=\u001B[39m roc_curve(y_true, y_score, sample_weight\u001B[38;5;241m=\u001B[39msample_weight)\n\u001B[0;32m    344\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m max_fpr \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m max_fpr \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n",
      "\u001B[1;31mValueError\u001B[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "source": [
    "print(len(y))\n",
    "X_train, test_x, y_train, test_lab = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "clf = DecisionTreeClassifier(max_depth=2, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "print(test_lab)\n",
    "print(y)\n",
    "roc_auc_score(test_lab, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "running the play function to check the ROC and AUC in the previous code"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'play' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mplay\u001B[49m(player, quincy, \u001B[38;5;241m4\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'play' is not defined"
     ]
    }
   ],
   "source": [
    "play(player, quincy, 4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}